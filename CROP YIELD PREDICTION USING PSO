import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error
from pyswarm import pso

# Load dataset
file_path = "/content/drive/MyDrive/archive (1)/Crop_recommendation.csv"
df = pd.read_csv(file_path)

# Encode categorical labels
label_encoder = LabelEncoder()
df['label'] = label_encoder.fit_transform(df['label'])

# Define features and target
X = df.drop(columns=['label'])
y = df['label']

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define objective function for PSO
def objective_function(params):
    max_depth, min_samples_split = int(params[0]), int(params[1])
    model = DecisionTreeRegressor(max_depth=max_depth, min_samples_split=min_samples_split, random_state=42)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    return mean_squared_error(y_test, y_pred)  # Minimize MSE

# Define search space
lb = [3, 2]  # Lower bounds (min depth, min samples split)
ub = [20, 10]  # Upper bounds (max depth, max samples split)

# Run PSO
best_params, best_mse = pso(objective_function, lb, ub, swarmsize=10, maxiter=5)

# Train final model with best parameters
best_max_depth, best_min_samples_split = int(best_params[0]), int(best_params[1])
final_model = DecisionTreeRegressor(max_depth=best_max_depth, min_samples_split=best_min_samples_split, random_state=42)
final_model.fit(X_train, y_train)

y_pred = final_model.predict(X_test)
final_mse = mean_squared_error(y_test, y_pred)

print(f"Best Parameters: max_depth={best_max_depth}, min_samples_split={best_min_samples_split}")
print(f"Final Model MSE: {final_mse}")
